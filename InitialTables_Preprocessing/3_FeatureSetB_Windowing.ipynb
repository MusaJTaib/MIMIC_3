{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSetB = pd.read_csv('FeatureSet/FS_48Hours.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert To hourly\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "def hour_rounder(t):\n",
    "    # Rounds to nearest hour by adding a timedelta hour if minute >= 30\n",
    "    return (t.replace(second=0, microsecond=0, minute=0, hour=t.hour)\n",
    "               +timedelta(hours=t.minute//30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSetB['date'] = pd.to_datetime(FeatureSetB.date, format='%Y-%m-%d')\n",
    "FeatureSetB['time'] = pd.to_datetime(FeatureSetB.time, format='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSetB['time'] = FeatureSetB['time'].apply(hour_rounder)\n",
    "FeatureSetB['time'] = pd.to_datetime(FeatureSetB['time']).dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSetB.drop(['date', 'time'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subject_id = pd.DataFrame()\n",
    "Subject_id = FeatureSetB.subject_id\n",
    "Subject_id.drop_duplicates(keep = 'first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for X in Subject_id:\n",
    "    Feature = pd.DataFrame()\n",
    "    Y = FeatureSetB.loc[FeatureSetB['subject_id'] == X]\n",
    "    Z = Y.shape\n",
    "    Rows = Z[0]\n",
    "    result.append((X, Rows))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregationFunc(tbl):\n",
    "    Subject_id = tbl['subject_id'].mode()\n",
    "    GCSEyesAgg = tbl['GCSEyes'].mode()\n",
    "    GCSMotorAgg = tbl['GCSMotor'].mode()\n",
    "    GCSVerbalAgg = tbl['GCSVerbal'].mode()\n",
    "    Bilrubin_LevelAgg = tbl['Bilrubin_Level'].mean()\n",
    "    BTAgg = tbl['BT'].mean()\n",
    "    FIO2Agg = tbl['FIO2'].mean()\n",
    "    HRAgg = tbl['HR'].mean()\n",
    "    PAO2Agg = tbl['PAO2'].mean()\n",
    "    Potassium_LevelAgg = tbl['Potassium_Level'].mean()\n",
    "    SBC_LevelAgg = tbl['SBC_Level'].mean()                 \n",
    "    SBPAgg = tbl['SBP'].mean()                 \n",
    "    Sodium_LevelAgg = tbl['Sodium_Level'].mean()           \n",
    "    SUN_LevelAgg = tbl['SUN_Level'].mean()               \n",
    "    UrinAgg = tbl['Urin'].mean()   \n",
    "    WBCC_LevelAgg = tbl['WBCC_Level'].mean()         \n",
    "    Service_typeAgg = tbl['Service_type'].mode()               \n",
    "    AgeAgg = tbl['Age'].mode()                       \n",
    "    MetaStaticAgg = tbl['MetaStatic'].mode()                  \n",
    "    HematologicAgg = tbl['Hematologic'].mode()                   \n",
    "    Procedure_typeAgg = tbl['Procedure_type'].mode()                  \n",
    "    X = pd.DataFrame({\n",
    "    'subject_id': Subject_id,\n",
    "    'Procedure_type': Procedure_typeAgg,\n",
    "    'Bilrubin_Level': Bilrubin_LevelAgg,\n",
    "    'BT': BTAgg,  \n",
    "    'FIO2': FIO2Agg,\n",
    "    'GCSEyes' : GCSEyesAgg,\n",
    "    'GCSMotor' :  GCSMotorAgg,\n",
    "    'GCSVerbal' : GCSVerbalAgg,\n",
    "    'HR' : HRAgg,\n",
    "    'PAO2': PAO2Agg, \n",
    "    'Potassium_Level': Potassium_LevelAgg,\n",
    "    'SBC_Level': SBC_LevelAgg,\n",
    "    'SBP': SBPAgg,\n",
    "    'Service_type': Service_typeAgg,\n",
    "    'Sodium_Level': Sodium_LevelAgg,         \n",
    "    'SUN_Level': SUN_LevelAgg,              \n",
    "    'Urin': UrinAgg,                      \n",
    "    'WBCC_Level': WBCC_LevelAgg, \n",
    "    'Age': AgeAgg,\n",
    "    'Hematologic' : HematologicAgg,\n",
    "    'MetaStatic' : MetaStaticAgg,          \n",
    "    })\n",
    "    if(len(X.index) != 1):\n",
    "        X.drop(1, inplace=True)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSetB['MetaStatic'] = FeatureSetB['MetaStatic'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSetB['Hematologic'] = FeatureSetB['Hematologic'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(result,columns =['subject_id','Rows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_G48 = result_df.drop(result_df.index[result_df['Rows'] <= 48])\n",
    "results_L48 = result_df.drop(result_df.index[result_df['Rows'] >= 48])\n",
    "results_E48 = result_df.drop(result_df.index[result_df['Rows'] != 48])\n",
    "results_G48.reset_index(drop=True,inplace=True)\n",
    "results_L48.reset_index(drop=True,inplace=True)\n",
    "results_E48.reset_index(drop=True,inplace=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = FeatureSetB.subject_id.isin(results_G48.subject_id)\n",
    "G48 = FeatureSetB[X1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " [Elapsed Time: 0:03:37] 100%|##############################| (Time:  0:03:37) \n"
     ]
    }
   ],
   "source": [
    "from math import floor\n",
    "import progressbar \n",
    "widgets=[' [', progressbar.Timer(), '] ',progressbar.Percentage(),progressbar.Bar(),' (', progressbar.ETA(), ') ',]\n",
    "i = 0\n",
    "FeatureSet = pd.DataFrame()\n",
    "for S1 in progressbar.progressbar(results_G48.subject_id, widgets=widgets):\n",
    "    #print('Subject_Id',S1)\n",
    "    Y = G48.loc[G48['subject_id'] == S1]\n",
    "    Y.reset_index(drop=True,inplace=True)\n",
    "    #Check = Y.iloc[3]\n",
    "    Rows = results_G48.Rows[i]\n",
    "    i = i+1\n",
    "    net = Rows - 48\n",
    "    net2 = Rows - 2*48\n",
    "    remove = list()\n",
    "    remove2 = list()\n",
    "    X1 =  pd.DataFrame()\n",
    "    X2 =  pd.DataFrame()\n",
    "    if(net2 <= 0):\n",
    "        S2 = 0\n",
    "        for SX in range(net):\n",
    "            #print('S2 = ',S2)\n",
    "            X1 = Y.iloc[[S2]]\n",
    "            X2 = Y.iloc[[S2+1]]\n",
    "            remove.append(S2+1)\n",
    "            frames = [X1, X2]\n",
    "            X3 = pd.concat(frames)\n",
    "            X4 = aggregationFunc(X3)\n",
    "            Y.iloc[S2] = X4\n",
    "            Y.iloc[S2+1] = X4\n",
    "            S2 = S2+2   \n",
    "            if(S2>=(Rows-1)):\n",
    "                break \n",
    "        Y.drop(remove, inplace=True)\n",
    "        Y.reset_index(drop=True,inplace=True)         \n",
    "    else:\n",
    "        S4 = 0\n",
    "        S3 = 0 \n",
    "        Loop = floor(Rows/2)\n",
    "        for SX in range(Loop):\n",
    "            #print('S4 = ',S4)\n",
    "            X1 = Y.iloc[S4]\n",
    "            X2 = Y.iloc[S4+1]\n",
    "            remove.append(S4+1)\n",
    "            frames = [X1, X2]\n",
    "            X3 = pd.concat(frames)\n",
    "            X4 = aggregationFunc(X3)\n",
    "            Y.iloc[S4] = X4\n",
    "            Y.iloc[S4+1] = X4\n",
    "            #Y.drop(S4+1, inplace=True) \n",
    "            S4 = S4+2\n",
    "        Y.drop(remove, inplace=True)\n",
    "        Y.reset_index(drop=True,inplace=True)\n",
    "        NRows = Y.shape\n",
    "        NRows = NRows[0]\n",
    "        net3 = NRows - 48\n",
    "        for SX in range(net3):\n",
    "            #print('S3 = ',S3)\n",
    "            X1 = Y.iloc[S3]\n",
    "            X2 = Y.iloc[S3+1]\n",
    "            remove2.append(S3+1)\n",
    "            frames = [X1, X2]\n",
    "            X3 = pd.concat(frames)\n",
    "            X4 = aggregationFunc(X3)\n",
    "            Y.iloc[S3] = X4\n",
    "            Y.iloc[S3+1] = X4 \n",
    "            S3 = S3+2\n",
    "            if(S3>=(NRows-1)):\n",
    "                break \n",
    "        Y.drop(remove2, inplace=True)\n",
    "        Y.reset_index(drop=True,inplace=True) \n",
    "    FeatureSet = pd.concat([FeatureSet,Y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = FeatureSetB.subject_id.isin(results_L48.subject_id)\n",
    "L48 = FeatureSetB[X2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " [Elapsed Time: 0:00:08] 100%|##############################| (Time:  0:00:08) \n"
     ]
    }
   ],
   "source": [
    "widgets=[' [', progressbar.Timer(), '] ',progressbar.Percentage(),progressbar.Bar(),' (', progressbar.ETA(), ') ',]\n",
    "i = 0\n",
    "FeatureSetL48 = pd.DataFrame()\n",
    "for S1 in progressbar.progressbar(results_L48.subject_id, widgets=widgets):\n",
    "    #print('Subject_Id',S1)\n",
    "    Y = L48.loc[L48['subject_id'] == S1]\n",
    "    Y.reset_index(drop=True,inplace=True)\n",
    "    #Check = Y.iloc[3]\n",
    "    Rows = results_L48.Rows[i]\n",
    "    NeededRows = 48 - Rows\n",
    "    new_index = pd.RangeIndex(NeededRows)\n",
    "    Filler_df = pd.DataFrame(np.nan, index=new_index, columns=Y.columns)\n",
    "    Filler_df.subject_id = S1\n",
    "    frames = [Y, Filler_df]\n",
    "    Y_New = pd.concat(frames)\n",
    "    FeatureSetL48 = pd.concat([FeatureSetL48,Y_New])\n",
    "    i = i+1\n",
    "FeatureSetL48.reset_index(drop=True,inplace=True) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add n blank rows\n",
    "X3 = FeatureSetB.subject_id.isin(results_E48.subject_id)\n",
    "E48 = FeatureSetB[X3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [FeatureSet, FeatureSetL48, E48]\n",
    "FeatureSet48 = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSetAGG = pd.DataFrame()\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "for S1 in Subject_id:\n",
    "    Y = FeatureSet48.loc[FeatureSet48['subject_id'] == S1]\n",
    "    X4 = aggregationFunc(Y)\n",
    "    Y['subject_id'] = Y['subject_id'].fillna(X4.subject_id[0])\n",
    "    Y['Bilrubin_Level'] = Y['Bilrubin_Level'].fillna(X4.Bilrubin_Level[0])\n",
    "    Y['BT'] = Y['BT'].fillna(X4.BT[0])\n",
    "    Y['subject_id'] = Y['subject_id'].fillna(X4.subject_id[0])\n",
    "    Y['GCSEyes'] = Y['GCSEyes'].fillna(X4.GCSEyes[0])\n",
    "    Y['GCSMotor'] = Y['GCSMotor'].fillna(X4.GCSMotor[0])\n",
    "    Y['GCSVerbal'] = Y['GCSVerbal'].fillna(X4.GCSVerbal[0])\n",
    "    Y['FIO2'] = Y['FIO2'].fillna(X4.FIO2[0])\n",
    "    Y['HR'] = Y['HR'].fillna(X4.HR[0])\n",
    "    Y['PAO2'] = Y['PAO2'].fillna(X4.PAO2[0])\n",
    "    Y['Potassium_Level'] = Y['Potassium_Level'].fillna(X4.Potassium_Level[0])\n",
    "    Y['SBC_Level'] = Y['SBC_Level'].fillna(X4.SBC_Level[0])      \n",
    "    Y['SBP'] = Y['SBP'].fillna(X4.SBP[0])        \n",
    "    Y['Sodium_Level'] = Y['Sodium_Level'].fillna(X4.Sodium_Level[0])        \n",
    "    Y['SUN_Level'] = Y['SUN_Level'].fillna(X4.SUN_Level[0])       \n",
    "    Y['Urin'] = Y['Urin'].fillna(X4.Urin[0])\n",
    "    Y['WBCC_Level'] = Y['WBCC_Level'].fillna(X4.WBCC_Level[0])        \n",
    "    Y['Service_type'] = Y['Service_type'].fillna(X4.Service_type[0])             \n",
    "    Y['Age'] = Y['Age'].fillna(X4.Age[0])\n",
    "    Y['MetaStatic'] = Y['MetaStatic'].fillna(X4.MetaStatic[0])              \n",
    "    Y['Hematologic'] =  Y['Hematologic'].fillna(X4.Hematologic[0])               \n",
    "    Y['Procedure_type'] = Y['Procedure_type'].fillna(X4.Procedure_type[0])\n",
    "    FeatureSetAGG = pd.concat([FeatureSetAGG,Y])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSetAGG.to_csv('FeatureSet/AD_48Hours.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48feb6360a00eb0f47f9c89bd4d436ba37b01dbe1c2db3c2c6dfcc0146625bee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
