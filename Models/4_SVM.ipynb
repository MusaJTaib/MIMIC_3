{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSetB = pd.read_csv('MIMIC_Windows/FSB_1Ws.csv')\n",
    "FeatureMortality = pd.read_csv('MIMIC_Windows/FSB_Mortality.csv')\n",
    "numberOfWindows = 1\n",
    "numberOfFeatures = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subject_id = pd.DataFrame()\n",
    "Subject_id = FeatureSetB.subject_id\n",
    "Subject_id.drop_duplicates(keep = 'first', inplace = True)\n",
    "Subject_id.reset_index(drop=True,inplace=True)\n",
    "NumSubjects = len(Subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FeatureMortality['subject_id'].equals(Subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSet = FeatureSetB.drop(['subject_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSet = FeatureSet.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = pd.DataFrame()\n",
    "Labels['Expired'] = FeatureMortality['Expired'] \n",
    "y_values = Labels.to_numpy()\n",
    "y_values = y_values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(FeatureSet)\n",
    "X_scaled = scaler.transform(FeatureSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nClients = NumSubjects\n",
    "featureArray = X_scaled.reshape(nClients,numberOfWindows*numberOfFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "\n",
    " \n",
    "acc_score = []\n",
    "re_score = []\n",
    "pre_score = []\n",
    "f_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(123)\n",
    "\n",
    "import sys\n",
    "mod=sys.modules[__name__]\n",
    "from sklearn import svm\n",
    "model = svm.SVC(kernel='poly')\n",
    "from sklearn import metrics\n",
    "\n",
    "acc_score = []\n",
    "re_score = []\n",
    "pre_score = []\n",
    "f_score = []\n",
    "auroc = []\n",
    "auprc = []\n",
    "\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "X = featureArray\n",
    "y = y_values\n",
    "resample = NeighbourhoodCleaningRule()\n",
    "k = 10\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "for train_ix, val_ix in skf.split(X,y):\n",
    "    # select rows\n",
    "    X_train, X_val = X[train_ix], X[val_ix]\n",
    "    y_train, y_val = y[train_ix], y[val_ix]\n",
    "\n",
    "    X_train,y_train = resample.fit_resample(X_train, y_train) \n",
    "\n",
    "    history4 = model.fit(X_train,y_train) \n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = list(map(lambda x: 0 if x<=0.5 else 1, y_pred))\n",
    "\n",
    "    y_actu = pd.Series(y_val)\n",
    "    y_pred = pd.Series(y_pred)\n",
    "    \n",
    "    f1_value = f1_score(y_actu, y_pred,pos_label = 1, average='binary') \n",
    "    sensitivity = recall_score(y_actu, y_pred,pos_label = 1, average='binary')\n",
    "    precision = precision_score(y_actu, y_pred,pos_label = 1, average='binary')\n",
    "    prc = average_precision_score(y_actu, y_pred,pos_label = 1)\n",
    "    roc = roc_auc_score(y_actu, y_pred)\n",
    "    accuracy = accuracy_score(y_actu, y_pred)\n",
    "    \n",
    "    acc_score.append(accuracy)\n",
    "    re_score.append(sensitivity)\n",
    "    pre_score.append(precision)\n",
    "    f_score.append(f1_value)\n",
    "    auroc.append(roc)\n",
    "    auprc.append(prc)\n",
    "   \n",
    "avg_acc_score = sum(acc_score)/k\n",
    "avg_recall_score = sum(re_score)/k\n",
    "avg_precision_score = sum(pre_score)/k\n",
    "avg_f1_score = sum(f_score)/k\n",
    "avg_roc_score = sum(auroc)/k\n",
    "avg_prc_score = sum(auprc)/k\n",
    "\n",
    "sensitivity = avg_recall_score\n",
    "precision = avg_precision_score\n",
    "accuracy = avg_acc_score\n",
    "f1_score = avg_f1_score\n",
    "auroc = avg_roc_score\n",
    "auprc = avg_prc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of each fold - [0.9108391608391608, 0.9090909090909091, 0.9073426573426573, 0.9003496503496503, 0.9003496503496503, 0.9055944055944056, 0.9073426573426573, 0.9090909090909091, 0.9020979020979021, 0.9036777583187391]\n",
      "Avg accuracy : 0.9055775660416643\n",
      "Recall of each fold - [0.43137254901960786, 0.49019607843137253, 0.5, 0.38461538461538464, 0.5384615384615384, 0.4423076923076923, 0.38461538461538464, 0.5384615384615384, 0.4807692307692308, 0.4117647058823529]\n",
      "Avg Reccall : 0.46025641025641023\n",
      "Precision of each fold - [0.5, 0.49019607843137253, 0.49056603773584906, 0.4444444444444444, 0.45901639344262296, 0.4791666666666667, 0.4878048780487805, 0.5, 0.46296296296296297, 0.45652173913043476]\n",
      "Avg Precision : 0.4770679200863134\n",
      "F1_Score of each fold - [0.4631578947368421, 0.49019607843137253, 0.49523809523809526, 0.4123711340206186, 0.4955752212389381, 0.45999999999999996, 0.4301075268817205, 0.5185185185185186, 0.4716981132075472, 0.4329896907216495]\n",
      "Avg F1_score : 0.46698522729953024\n",
      "AUROC of each fold - 0.7050409099857278\n",
      "Avg AUROC : 0.7050409099857278\n",
      "AUPRC of each fold - 0.26865634426908336\n",
      "Avg AUPRC : 0.26865634426908336\n"
     ]
    }
   ],
   "source": [
    "print('accuracy of each fold - {}'.format(acc_score))\n",
    "print('Avg accuracy : {}'.format(avg_acc_score))\n",
    "print('Recall of each fold - {}'.format(re_score))\n",
    "print('Avg Reccall : {}'.format(avg_recall_score))\n",
    "print('Precision of each fold - {}'.format(pre_score))\n",
    "print('Avg Precision : {}'.format(avg_precision_score))\n",
    "print('F1_Score of each fold - {}'.format(f_score))\n",
    "print('Avg F1_score : {}'.format(avg_f1_score))\n",
    "print('AUROC of each fold - {}'.format(auroc))\n",
    "print('Avg AUROC : {}'.format(avg_roc_score))\n",
    "print('AUPRC of each fold - {}'.format(auprc))\n",
    "print('Avg AUPRC : {}'.format(avg_prc_score))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/MusaJTaib/Desktop/Education/Semesters/Summer/Codes/Mimic_Codes/Testing_SVM.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/MusaJTaib/Desktop/Education/Semesters/Summer/Codes/Mimic_Codes/Testing_SVM.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatetime\u001b[39;00m \u001b[39mimport\u001b[39;00m datetime\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/MusaJTaib/Desktop/Education/Semesters/Summer/Codes/Mimic_Codes/Testing_SVM.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m csv_columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mmodel-type\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39msensitivity\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mf1-score\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mAUROC\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mAUPRC\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mNumberOfWindows\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mEpochs\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/MusaJTaib/Desktop/Education/Semesters/Summer/Codes/Mimic_Codes/Testing_SVM.ipynb#X20sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m dict_data \u001b[39m=\u001b[39m [{\u001b[39m'\u001b[39m\u001b[39mmodel-type\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mSVM\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m'\u001b[39m: precision,\u001b[39m'\u001b[39m\u001b[39msensitivity\u001b[39m\u001b[39m'\u001b[39m: sensitivity,\u001b[39m'\u001b[39m\u001b[39mf1-score\u001b[39m\u001b[39m'\u001b[39m: f1_score,\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m: accuracy,\u001b[39m'\u001b[39m\u001b[39mNumberOfWindows\u001b[39m\u001b[39m'\u001b[39m:numberOfWindows,\u001b[39m\"\u001b[39m\u001b[39mEpochs\u001b[39m\u001b[39m\"\u001b[39m:ep,\u001b[39m'\u001b[39m\u001b[39mAUROC\u001b[39m\u001b[39m'\u001b[39m:auroc,\u001b[39m'\u001b[39m\u001b[39mAUPRC\u001b[39m\u001b[39m'\u001b[39m:auprc}]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/MusaJTaib/Desktop/Education/Semesters/Summer/Codes/Mimic_Codes/Testing_SVM.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m metric_file \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mResults/Results_SVM.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/MusaJTaib/Desktop/Education/Semesters/Summer/Codes/Mimic_Codes/Testing_SVM.ipynb#X20sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m file_exists \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(metric_file)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ep' is not defined"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "\n",
    "csv_columns = ['model-type','precision','sensitivity','f1-score','accuracy','AUROC','AUPRC','NumberOfWindows']\n",
    "dict_data = [{'model-type':'SVM', 'precision': precision,'sensitivity': sensitivity,'f1-score': f1_score,'accuracy': accuracy,'NumberOfWindows':numberOfWindows,'AUROC':auroc,'AUPRC':auprc}]\n",
    "metric_file = \"Results/Results_SVM.csv\"\n",
    "\n",
    "file_exists = os.path.isfile(metric_file)\n",
    "try:\n",
    "    with open(metric_file, 'a') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        for data in dict_data:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48feb6360a00eb0f47f9c89bd4d436ba37b01dbe1c2db3c2c6dfcc0146625bee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
