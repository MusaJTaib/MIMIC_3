{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSetB = pd.read_csv('MIMIC_Windows/FSB_10Ws.csv')\n",
    "FeatureMortality = pd.read_csv('MIMIC_Windows/FSB_Mortality.csv')\n",
    "numberOfWindows = 10\n",
    "numberOfFeatures = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subject_id = pd.DataFrame()\n",
    "Subject_id = FeatureSetB.subject_id\n",
    "Subject_id.drop_duplicates(keep = 'first', inplace = True)\n",
    "Subject_id.reset_index(drop=True,inplace=True)\n",
    "NumSubjects = len(Subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FeatureMortality['subject_id'].equals(Subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSet = FeatureSetB.drop(['subject_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSet = FeatureSet.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = pd.DataFrame()\n",
    "Labels['Expired'] = FeatureMortality['Expired'] \n",
    "y_values = Labels.to_numpy()\n",
    "y_values = y_values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "nClients = NumSubjects\n",
    "featureArray = FeatureSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn import metrics\n",
    "from keras.layers import LSTM\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "mod=sys.modules[__name__]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "PR = [\n",
    "      keras.metrics.AUC(name='prc',multi_label=False,curve='PR'),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 100)               48400     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,601\n",
      "Trainable params: 58,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(1234)  # Fixing the seed values for reproduciblity\n",
    "\n",
    "# Model Archieteture\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(numberOfWindows,numberOfFeatures)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.001) \n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=PR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc_score = []\n",
    "re_score = []\n",
    "pre_score = []\n",
    "f_score = []\n",
    "auroc = []\n",
    "auprc = []\n",
    "\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "from imblearn.under_sampling import TomekLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 08:11:42.928091: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-02 08:11:43.179639: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-02 08:11:43.356050: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 3s 21ms/step - loss: 0.2602 - prc: 0.3409\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.2112 - prc: 0.5013\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.1963 - prc: 0.5571\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1837 - prc: 0.6099\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1728 - prc: 0.6497\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.1657 - prc: 0.6689\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.1552 - prc: 0.7093\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.1494 - prc: 0.7271\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1355 - prc: 0.7707\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1290 - prc: 0.7881\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1222 - prc: 0.8061\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1142 - prc: 0.8298\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.1051 - prc: 0.8536\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0974 - prc: 0.8688\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0883 - prc: 0.8929\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0826 - prc: 0.9048\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0766 - prc: 0.9154\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0705 - prc: 0.9268\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0619 - prc: 0.9435\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0566 - prc: 0.9516\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0499 - prc: 0.9609\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0494 - prc: 0.9612\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0422 - prc: 0.9716\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0398 - prc: 0.9738\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0385 - prc: 0.9760\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0288 - prc: 0.9857\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0314 - prc: 0.9833\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0263 - prc: 0.9862\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0240 - prc: 0.9887\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0219 - prc: 0.9898\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0201 - prc: 0.9919\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0196 - prc: 0.9904\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0204 - prc: 0.9895\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0179 - prc: 0.9937\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0161 - prc: 0.9942\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0128 - prc: 0.9929\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0141 - prc: 0.9956\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0102 - prc: 0.9956\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0070 - prc: 0.9977\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0117 - prc: 0.9924\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0129 - prc: 0.9935\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0103 - prc: 0.9968\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0118 - prc: 0.9955\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0105 - prc: 0.9924\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0088 - prc: 0.9986\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0074 - prc: 0.9960\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0091 - prc: 0.9958\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0079 - prc: 0.9965\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0105 - prc: 0.9912\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0088 - prc: 0.9964\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0057 - prc: 0.9971\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0080 - prc: 0.9974\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0065 - prc: 0.9992\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0104 - prc: 0.9948\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0117 - prc: 0.9931\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0045 - prc: 0.9996\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0089 - prc: 0.9988\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0087 - prc: 0.9948\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0083 - prc: 0.9967\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0043 - prc: 0.9980\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0118 - prc: 0.9951\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0048 - prc: 0.9971\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0109 - prc: 0.9970\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0029 - prc: 0.9998\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0077 - prc: 0.9954\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0081 - prc: 0.9944\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0053 - prc: 0.9997\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0028 - prc: 0.9999\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0113 - prc: 0.9883\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0029 - prc: 0.9998\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0065 - prc: 0.9931\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0069 - prc: 0.9955\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0072 - prc: 0.9977\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0047 - prc: 0.9997\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0046 - prc: 0.9997\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0067 - prc: 0.9960\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0022 - prc: 0.9999\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0112 - prc: 0.9943\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0054 - prc: 0.9972\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0021 - prc: 0.9999\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0108 - prc: 0.9941\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0030 - prc: 0.9998\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0097 - prc: 0.9909\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0038 - prc: 0.9998\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0111 - prc: 0.9940\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0075 - prc: 0.9936\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0057 - prc: 0.9980\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0032 - prc: 0.9981\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0031 - prc: 0.9998\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0071 - prc: 0.9930\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0066 - prc: 0.9980\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0087 - prc: 0.9961\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0047 - prc: 0.9997\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0056 - prc: 0.9973\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0036 - prc: 0.9998\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0039 - prc: 0.9998\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0019 - prc: 0.9999\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0031 - prc: 0.9998\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0045 - prc: 0.9963\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0072 - prc: 0.9962\n",
      "13/36 [=========>....................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 08:13:50.988643: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-09-02 08:13:51.048674: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 5ms/step\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.2940 - prc: 0.7930\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1119 - prc: 0.8998\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0634 - prc: 0.9383\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0463 - prc: 0.9648\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0414 - prc: 0.9674\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0286 - prc: 0.9812\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0241 - prc: 0.9849\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0193 - prc: 0.9912\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0175 - prc: 0.9917\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0171 - prc: 0.9929\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0122 - prc: 0.9956\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0134 - prc: 0.9965\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0143 - prc: 0.9883\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0080 - prc: 0.9963\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0105 - prc: 0.9951\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0094 - prc: 0.9965\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0062 - prc: 0.9960\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0058 - prc: 0.9976\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0093 - prc: 0.9964\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0032 - prc: 0.9999\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0083 - prc: 0.9957\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0048 - prc: 0.9995\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0071 - prc: 0.9962\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0089 - prc: 0.9928\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0058 - prc: 0.9978\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0075 - prc: 0.9977\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0066 - prc: 0.9971\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0028 - prc: 0.9981\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0056 - prc: 0.9955\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0060 - prc: 0.9979\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0022 - prc: 0.9999\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0022 - prc: 0.9999\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0084 - prc: 0.9954\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0063 - prc: 0.9980\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0038 - prc: 0.9973\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0111 - prc: 0.9917\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0075 - prc: 0.9930\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0024 - prc: 0.9999\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0030 - prc: 0.9981\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0018 - prc: 0.9999\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0026 - prc: 0.9999\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0041 - prc: 0.9980\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0042 - prc: 0.9956\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0022 - prc: 0.9999\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0076 - prc: 0.9955\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0120 - prc: 0.9911\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0092 - prc: 0.9933\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 4.2306e-04 - prc: 1.0000\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0063 - prc: 0.9979\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0020 - prc: 0.9981\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0017 - prc: 1.0000\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0073 - prc: 0.9973\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0056 - prc: 0.9956\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0019 - prc: 1.0000\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0026 - prc: 0.9999\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0030 - prc: 0.9999\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0093 - prc: 0.9937\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0045 - prc: 0.9957\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0025 - prc: 0.9999\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0047 - prc: 0.9975\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 4.6940e-04 - prc: 1.0000\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0030 - prc: 0.9999\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0066 - prc: 0.9939\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0017 - prc: 1.0000\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0086 - prc: 0.9957\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0039 - prc: 0.9981\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0054 - prc: 0.9939\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0103 - prc: 0.9932\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0050 - prc: 0.9957\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0065 - prc: 0.9962\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 2s 24ms/step - loss: 5.5772e-04 - prc: 1.0000\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0016 - prc: 1.0000\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0025 - prc: 0.9999\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0096 - prc: 0.9930\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0083 - prc: 0.9962\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0060 - prc: 0.9980\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0016 - prc: 1.0000\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0014 - prc: 1.0000\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 3.3901e-04 - prc: 1.0000\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0066 - prc: 0.9956\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 4.5319e-04 - prc: 1.0000\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0067 - prc: 0.9956\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 9.9915e-05 - prc: 1.0000\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0059 - prc: 0.9945\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0027 - prc: 0.9999\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0068 - prc: 0.9938\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0032 - prc: 0.9981\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0040 - prc: 0.9975\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0020 - prc: 0.9999\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0034 - prc: 0.9975\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0035 - prc: 0.9975\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0017 - prc: 0.9982\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0073 - prc: 0.9957\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0023 - prc: 0.9975\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0034 - prc: 0.9981\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0070 - prc: 0.9975\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0047 - prc: 0.9951\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0046 - prc: 0.9957\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0085 - prc: 0.9963\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0044 - prc: 0.9981\n",
      "36/36 [==============================] - 0s 5ms/step\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.1095 - prc: 0.9155\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0334 - prc: 0.9738\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0281 - prc: 0.9766\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0089 - prc: 0.9965\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0105 - prc: 0.9934\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0115 - prc: 0.9907\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0089 - prc: 0.9935\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0055 - prc: 0.9996\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0051 - prc: 0.9948\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0036 - prc: 0.9998\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0037 - prc: 0.9974\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0035 - prc: 0.9998\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0068 - prc: 0.9955\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0081 - prc: 0.9960\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0038 - prc: 0.9974\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0018 - prc: 0.9999\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0027 - prc: 0.9999\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0063 - prc: 0.9960\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0014 - prc: 0.9999\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0013 - prc: 1.0000\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0046 - prc: 0.9956\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 4.7189e-04 - prc: 1.0000\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0058 - prc: 0.9974\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0046 - prc: 0.9981\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0024 - prc: 0.9999\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0091 - prc: 0.9954\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0087 - prc: 0.9978\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 8.4516e-04 - prc: 1.0000\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0012 - prc: 1.0000\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0043 - prc: 0.9981\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0059 - prc: 0.9981\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0061 - prc: 0.9974\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0020 - prc: 0.9999\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0054 - prc: 0.9956\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0053 - prc: 0.9933\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0115 - prc: 0.9907\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0114 - prc: 0.9895\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0058 - prc: 0.9938\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0083 - prc: 0.9961\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0042 - prc: 0.9956\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0056 - prc: 0.9962\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0020 - prc: 0.9999\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0049 - prc: 0.9975\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0082 - prc: 0.9938\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0054 - prc: 0.9981\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0033 - prc: 0.9975\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0042 - prc: 0.9981\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0020 - prc: 1.0000\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0032 - prc: 0.9999\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0034 - prc: 0.9981\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0017 - prc: 1.0000\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0104 - prc: 0.9929\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0038 - prc: 0.9981\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0018 - prc: 0.9999\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0068 - prc: 0.9950\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0021 - prc: 0.9981\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0118 - prc: 0.9919\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0013 - prc: 1.0000\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0012 - prc: 1.0000\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0029 - prc: 0.9975\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0012 - prc: 1.0000\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0059 - prc: 0.9939\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 7.9816e-04 - prc: 1.0000\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0077 - prc: 0.9926\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0016 - prc: 1.0000\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0092 - prc: 0.9931\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0045 - prc: 0.9981\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 4.6404e-04 - prc: 1.0000\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0064 - prc: 0.9956\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0031 - prc: 0.9976\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 8.1647e-04 - prc: 1.0000\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 2s 32ms/step - loss: 0.0053 - prc: 0.9963\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.0046 - prc: 0.9963\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 9.5171e-04 - prc: 1.0000\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 2s 29ms/step - loss: 0.0088 - prc: 0.9949\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 7.7169e-04 - prc: 1.0000\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 4.1784e-04 - prc: 1.0000\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0083 - prc: 0.9932\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 4.2723e-04 - prc: 1.0000\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 2s 25ms/step - loss: 0.0029 - prc: 0.9957\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0015 - prc: 0.9982\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0039 - prc: 0.9999\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0072 - prc: 0.9944\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0051 - prc: 0.9974\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 8.9318e-04 - prc: 1.0000\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0033 - prc: 0.9999\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0022 - prc: 0.9981\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0014 - prc: 1.0000\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0024 - prc: 0.9999\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0055 - prc: 0.9975\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 8.7110e-04 - prc: 1.0000\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0022 - prc: 0.9982\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0079 - prc: 0.9957\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0074 - prc: 0.9956\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0011 - prc: 1.0000\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0037 - prc: 0.9975\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0134 - prc: 0.9864\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0071 - prc: 0.9962\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0028 - prc: 0.9999\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0106 - prc: 0.9901\n",
      "36/36 [==============================] - 0s 5ms/step\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0998 - prc: 0.9379\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0276 - prc: 0.9833\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0112 - prc: 0.9965\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0118 - prc: 0.9935\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0059 - prc: 0.9963\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0021 - prc: 0.9999\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0134 - prc: 0.9926\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 20ms/step - loss: 0.0111 - prc: 0.9905\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 2s 22ms/step - loss: 0.0041 - prc: 0.9981\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0026 - prc: 0.9975\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0020 - prc: 0.9999\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0015 - prc: 1.0000\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 6.6251e-04 - prc: 1.0000\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0029 - prc: 0.9999\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0038 - prc: 0.9963\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0055 - prc: 0.9997\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0019 - prc: 0.9982\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0051 - prc: 0.9951\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0062 - prc: 0.9963\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0017 - prc: 0.9976\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0150 - prc: 0.9930\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0040 - prc: 0.9976\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0037 - prc: 0.9975\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 5.2000e-04 - prc: 1.0000\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0093 - prc: 0.9937\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0068 - prc: 0.9962\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0056 - prc: 0.9975\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0043 - prc: 0.9957\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0092 - prc: 0.9895\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0042 - prc: 0.9956\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0018 - prc: 1.0000\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0055 - prc: 0.9982\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0057 - prc: 0.9950\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0039 - prc: 0.9981\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 9.1062e-04 - prc: 1.0000\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0040 - prc: 0.9981\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0040 - prc: 0.9975\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0026 - prc: 0.9975\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0039 - prc: 0.9998\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0068 - prc: 0.9963\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0063 - prc: 0.9951\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0029 - prc: 0.9975\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 7.4755e-04 - prc: 1.0000\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0044 - prc: 0.9981\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0039 - prc: 0.9980\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0019 - prc: 0.9999\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0072 - prc: 0.9939\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0040 - prc: 0.9957\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 6.9395e-04 - prc: 1.0000\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0035 - prc: 0.9981\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0015 - prc: 1.0000\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0015 - prc: 0.9976\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 3.1305e-04 - prc: 1.0000\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0032 - prc: 0.9981\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 9.8498e-04 - prc: 1.0000\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0096 - prc: 0.9944\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 8.6939e-04 - prc: 1.0000\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0016 - prc: 0.9982\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 4.9140e-04 - prc: 1.0000\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0014 - prc: 0.9982\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0017 - prc: 1.0000\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0039 - prc: 0.9981\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0035 - prc: 0.9981\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0098 - prc: 0.9908\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0090 - prc: 0.9957\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0054 - prc: 0.9956\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 6.0911e-04 - prc: 1.0000\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0035 - prc: 0.9957\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0083 - prc: 0.9956\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0081 - prc: 0.9962\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0056 - prc: 0.9939\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0069 - prc: 0.9938\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0020 - prc: 0.9975\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0020 - prc: 0.9976\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0036 - prc: 0.9951\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0019 - prc: 0.9975\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0012 - prc: 1.0000\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0019 - prc: 1.0000\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0023 - prc: 0.9982\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0125 - prc: 0.9939\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0089 - prc: 0.9938\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0087 - prc: 0.9956\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 2s 21ms/step - loss: 9.2708e-04 - prc: 1.0000\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 2.5748e-04 - prc: 1.0000\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0014 - prc: 0.9982\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0081 - prc: 0.9963\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0059 - prc: 0.9980\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0058 - prc: 0.9975\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0020 - prc: 1.0000\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0026 - prc: 0.9981\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0055 - prc: 0.9975\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0021 - prc: 0.9999\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0043 - prc: 0.9963\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0040 - prc: 0.9981\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0050 - prc: 0.9975\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0088 - prc: 0.9957\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0028 - prc: 0.9976\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0027 - prc: 1.0000\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0133 - prc: 0.9913\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0037 - prc: 0.9974\n",
      "36/36 [==============================] - 0s 4ms/step\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0558 - prc: 0.9704\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0110 - prc: 0.9904\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0063 - prc: 0.9979\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0057 - prc: 0.9980\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0034 - prc: 0.9981\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0049 - prc: 0.9956\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0026 - prc: 0.9981\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0036 - prc: 0.9975\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0035 - prc: 0.9981\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0058 - prc: 0.9962\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0031 - prc: 0.9975\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0024 - prc: 0.9999\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0022 - prc: 0.9999\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0054 - prc: 0.9980\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0015 - prc: 1.0000\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0013 - prc: 0.9982\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0036 - prc: 0.9976\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0029 - prc: 0.9981\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 2.8405e-04 - prc: 1.0000\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 3.9697e-04 - prc: 1.0000\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0016 - prc: 0.9976\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0098 - prc: 0.9933\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 8.3389e-04 - prc: 1.0000\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 6.3942e-05 - prc: 1.0000\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0012 - prc: 1.0000\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0012 - prc: 1.0000\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0019 - prc: 0.9982\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0025 - prc: 0.9982\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.2221e-05 - prc: 1.0000\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0039 - prc: 0.9981\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0069 - prc: 0.9951\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 4.9492e-05 - prc: 1.0000\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0106 - prc: 0.9938\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 9.8467e-04 - prc: 1.0000\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.8606e-05 - prc: 1.0000\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0108 - prc: 0.9963\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0027 - prc: 0.9975\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0128 - prc: 0.9915\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0014 - prc: 0.9982\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0050 - prc: 0.9981\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0018 - prc: 1.0000\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0090 - prc: 0.9939\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0052 - prc: 0.9982\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 4.1956e-04 - prc: 1.0000\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 3.7389e-04 - prc: 1.0000\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0091 - prc: 0.9933\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 4.1611e-04 - prc: 1.0000\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 1.9745e-04 - prc: 1.0000\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0042 - prc: 0.9952\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0013 - prc: 1.0000\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0034 - prc: 0.9957\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0011 - prc: 1.0000\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0037 - prc: 0.9975\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0011 - prc: 1.0000\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0020 - prc: 1.0000\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0118 - prc: 0.9951\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0041 - prc: 0.9981\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0055 - prc: 0.9963\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 1s 19ms/step - loss: 0.0025 - prc: 0.9982\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0026 - prc: 0.9976\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0034 - prc: 0.9976\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0026 - prc: 0.9981\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 5.4827e-04 - prc: 1.0000\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0031 - prc: 0.9999\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.8765e-04 - prc: 1.0000\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0015 - prc: 1.0000\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0147 - prc: 0.9920\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0028 - prc: 0.9981\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 4.5251e-04 - prc: 1.0000\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0044 - prc: 0.9975\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 5.0456e-04 - prc: 1.0000\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0133 - prc: 0.9933\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0018 - prc: 0.9976\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0022 - prc: 0.9982\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.3720e-04 - prc: 1.0000\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0036 - prc: 0.9975\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 3.4841e-04 - prc: 1.0000\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0056 - prc: 0.9952\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0023 - prc: 0.9981\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 0.0011 - prc: 1.0000\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 1s 18ms/step - loss: 9.1739e-06 - prc: 1.0000\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0026 - prc: 0.9976\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 7.9853e-04 - prc: 1.0000\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0058 - prc: 0.9945\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0091 - prc: 0.9933\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0024 - prc: 1.0000\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0011 - prc: 1.0000\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.0134e-05 - prc: 1.0000\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0024 - prc: 0.9982\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 7.1376e-04 - prc: 1.0000\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0049 - prc: 0.9963\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.1437e-05 - prc: 1.0000\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.2777e-05 - prc: 1.0000\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0088 - prc: 0.9933\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0028 - prc: 0.9976\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0049 - prc: 0.9981\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0022 - prc: 1.0000\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0152 - prc: 0.9909\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0021 - prc: 1.0000\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0148 - prc: 0.9902\n",
      "36/36 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "resample = NeighbourhoodCleaningRule() \n",
    "Nresample = TomekLinks()\n",
    "\n",
    "X = featureArray\n",
    "y = y_values\n",
    "\n",
    "k = 5\n",
    "ep = 75\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "Train_shape = X.shape\n",
    "X = X.reshape(int(Train_shape[0]/numberOfWindows),numberOfWindows,numberOfFeatures)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "# enumerate the splits and summarize the distributions\n",
    "\n",
    "for train_ix, val_ix in skf.split(X,y):\n",
    "    # select rows\n",
    "    X_train, X_val = X[train_ix], X[val_ix]\n",
    "    y_train, y_val = y[train_ix], y[val_ix]\n",
    "    # summarize train and test composition\n",
    "\n",
    "    resample.fit_resample(X_train[:,:,0], y_train)\n",
    "    X_train = X_train[resample.sample_indices_]\n",
    "    y_train = y_train[resample.sample_indices_]\n",
    "\n",
    "    history4 = model.fit(X_train,y_train, epochs = ep,batch_size=64)\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = list(map(lambda x: 0 if x<0.5 else 1, y_pred))\n",
    "    #class_labels = np.argmax(y_pred, axis=1)\n",
    "    y_actu = pd.Series(y_val)\n",
    "    y_pred = pd.Series(y_pred)\n",
    "     \n",
    "    sensitivity = recall_score(y_actu, y_pred,pos_label = 1, average='binary')\n",
    "    precision = precision_score(y_actu, y_pred,pos_label = 1, average='binary')\n",
    "    f1_value = f1_score(y_actu, y_pred,pos_label = 1, average='binary')\n",
    "    prc = average_precision_score(y_actu, y_pred,pos_label = 1)\n",
    "    roc = roc_auc_score(y_actu, y_pred)\n",
    "    accuracy = accuracy_score(y_actu, y_pred)\n",
    "    \n",
    "    acc_score.append(accuracy)\n",
    "    re_score.append(sensitivity)\n",
    "    pre_score.append(precision)\n",
    "    f_score.append(f1_value)\n",
    "    auroc.append(roc)\n",
    "    auprc.append(prc)\n",
    "   \n",
    "avg_acc_score = sum(acc_score)/k\n",
    "avg_recall_score = sum(re_score)/k\n",
    "avg_precision_score = sum(pre_score)/k\n",
    "avg_f1_score = sum(f_score)/k\n",
    "avg_roc_score = sum(auroc)/k\n",
    "avg_prc_score = sum(auprc)/k\n",
    "\n",
    "\n",
    "sensitivity = avg_recall_score\n",
    "precision = avg_precision_score\n",
    "accuracy = avg_acc_score\n",
    "f1_score = avg_f1_score\n",
    "auroc = avg_roc_score\n",
    "auprc = avg_prc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of each fold - [0.8977272727272727, 0.958916083916084, 0.9711538461538461, 0.9842657342657343, 0.984251968503937]\n",
      "Avg accuracy : 0.9592629811133747\n",
      "Recall of each fold - [0.3300970873786408, 0.7184466019417476, 0.7884615384615384, 0.875, 0.8737864077669902]\n",
      "Avg Reccall : 0.7171583271097834\n",
      "Precision of each fold - [0.4146341463414634, 0.8043478260869565, 0.8817204301075269, 0.9479166666666666, 0.9473684210526315]\n",
      "Avg Precision : 0.799197498051049\n",
      "F1_Score of each fold - [0.3675675675675676, 0.7589743589743588, 0.83248730964467, 0.91, 0.909090909090909]\n",
      "Avg F1_score : 0.755624029055501\n",
      "AUROC of each fold - 0.8502198751487733\n",
      "Avg AUROC : 0.8502198751487733\n",
      "AUPRC of each fold - 0.6389620371280506\n",
      "Avg AUPRC : 0.6389620371280506\n"
     ]
    }
   ],
   "source": [
    "print('accuracy of each fold - {}'.format(acc_score))\n",
    "print('Avg accuracy : {}'.format(avg_acc_score))\n",
    "print('Recall of each fold - {}'.format(re_score))\n",
    "print('Avg Reccall : {}'.format(avg_recall_score))\n",
    "print('Precision of each fold - {}'.format(pre_score))\n",
    "print('Avg Precision : {}'.format(avg_precision_score))\n",
    "print('F1_Score of each fold - {}'.format(f_score))\n",
    "print('Avg F1_score : {}'.format(avg_f1_score))\n",
    "print('AUROC of each fold - {}'.format(auroc))\n",
    "print('Avg AUROC : {}'.format(avg_roc_score))\n",
    "print('AUPRC of each fold - {}'.format(auprc))\n",
    "print('Avg AUPRC : {}'.format(avg_prc_score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "\n",
    "csv_columns = ['model-type','precision','sensitivity','f1-score','accuracy','AUROC','AUPRC','NumberOfWindows','Epochs']\n",
    "dict_data = [{'model-type':'LSTM', 'precision': precision,'sensitivity': sensitivity,'f1-score': f1_score,'accuracy': accuracy,'NumberOfWindows':numberOfWindows,\"Epochs\":ep,'AUROC':auroc,'AUPRC':auprc}]\n",
    "metric_file = \"Results/Results_LSTM.csv\"\n",
    "\n",
    "file_exists = os.path.isfile(metric_file)\n",
    "try:\n",
    "    with open(metric_file, 'a') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        for data in dict_data:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48feb6360a00eb0f47f9c89bd4d436ba37b01dbe1c2db3c2c6dfcc0146625bee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
