{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSetB = pd.read_csv('MIMIC_Windows/FSB_1Ws.csv')\n",
    "FeatureMortality = pd.read_csv('MIMIC_Windows/FSB_Mortality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfWindows = 1\n",
    "numberOfFeatures = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Subject_id = pd.DataFrame()\n",
    "Subject_id = FeatureSetB.subject_id\n",
    "Subject_id.drop_duplicates(keep = 'first', inplace = True)\n",
    "Subject_id.reset_index(drop=True,inplace=True)\n",
    "NumSubjects = len(Subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FeatureMortality['subject_id'].equals(Subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSet = FeatureSetB.drop(['subject_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSet = FeatureSet.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = pd.DataFrame()\n",
    "Labels['Expired'] = FeatureMortality['Expired'] \n",
    "y_values = Labels.to_numpy()\n",
    "y_values = y_values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nClients = NumSubjects\n",
    "X = FeatureSet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import regularizers, optimizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn import metrics\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PR = [\n",
    "      keras.metrics.AUC(name='prc',multi_label=True,curve='PR'),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 1, 64)             1344      \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1, 64)             4160      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 64)             0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 1, 64)            0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               6500      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,105\n",
      "Trainable params: 12,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 08:41:37.048582: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-09-02 08:41:37.048740: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(1234)\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=1, activation='relu', input_shape=(numberOfWindows,numberOfFeatures)))#,padding = 'same'))\n",
    "model.add(Conv1D(filters=64, kernel_size=1, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.001) \n",
    "model.compile(loss='BinaryCrossentropy', optimizer=opt, metrics=PR)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from imblearn.under_sampling import NeighbourhoodCleaningRule\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "acc_score = []\n",
    "re_score = []\n",
    "pre_score = []\n",
    "f_score = []\n",
    "auroc = []\n",
    "auprc = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 08:41:37.580653: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-09-02 08:41:38.047418: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 2s 16ms/step - loss: 0.3283 - prc: 0.1634\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.2299 - prc: 0.4441\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.2134 - prc: 0.4948\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.2016 - prc: 0.5316\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1947 - prc: 0.5529\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1900 - prc: 0.5760\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1796 - prc: 0.6228\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.1765 - prc: 0.6259\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1692 - prc: 0.6596\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.1682 - prc: 0.6533\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.1642 - prc: 0.6679\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1579 - prc: 0.6870\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1548 - prc: 0.7021\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1470 - prc: 0.7190\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1444 - prc: 0.7291\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1449 - prc: 0.7354\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.1419 - prc: 0.7364\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.1346 - prc: 0.7686\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1318 - prc: 0.7717\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1304 - prc: 0.7730\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.1250 - prc: 0.7947\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.1239 - prc: 0.7928\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.1189 - prc: 0.8131\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1200 - prc: 0.8059\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.1132 - prc: 0.8284\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.1168 - prc: 0.8144\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1096 - prc: 0.8351\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1061 - prc: 0.8444\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1061 - prc: 0.8433\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.1031 - prc: 0.8624\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0988 - prc: 0.8636\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0957 - prc: 0.8717\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0937 - prc: 0.8770\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0889 - prc: 0.8901\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0872 - prc: 0.8919\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0878 - prc: 0.8907\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0838 - prc: 0.8992\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0817 - prc: 0.9058\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0826 - prc: 0.9020\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0836 - prc: 0.8956\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0822 - prc: 0.9016\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0768 - prc: 0.9110\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0724 - prc: 0.9227\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0704 - prc: 0.9292\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0657 - prc: 0.9353\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0648 - prc: 0.9385\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0585 - prc: 0.9513\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0636 - prc: 0.9410\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0616 - prc: 0.9436\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0610 - prc: 0.9445\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0678 - prc: 0.9334\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0608 - prc: 0.9457\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0543 - prc: 0.9566\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0523 - prc: 0.9585\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0585 - prc: 0.9475\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0534 - prc: 0.9565\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0517 - prc: 0.9577\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0477 - prc: 0.9662\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0560 - prc: 0.9488\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0539 - prc: 0.9551\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0537 - prc: 0.9584\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0504 - prc: 0.9632\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0452 - prc: 0.9688\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0436 - prc: 0.9704\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0438 - prc: 0.9713\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0388 - prc: 0.9773\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0404 - prc: 0.9743\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0453 - prc: 0.9653\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0381 - prc: 0.9742\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0363 - prc: 0.9763\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0434 - prc: 0.9683\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0378 - prc: 0.9776\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0376 - prc: 0.9777\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0411 - prc: 0.9732\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0381 - prc: 0.9753\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0381 - prc: 0.9778\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0353 - prc: 0.9806\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0392 - prc: 0.9724\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0322 - prc: 0.9844\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0319 - prc: 0.9836\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0298 - prc: 0.9855\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0387 - prc: 0.9728\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0297 - prc: 0.9865\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0309 - prc: 0.9845\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0430 - prc: 0.9691\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0287 - prc: 0.9857\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0314 - prc: 0.9847\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0310 - prc: 0.9836\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0267 - prc: 0.9895\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0279 - prc: 0.9872\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0278 - prc: 0.9872\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0262 - prc: 0.9889\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0264 - prc: 0.9884\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0278 - prc: 0.9870\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0254 - prc: 0.9894\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0341 - prc: 0.9760\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0271 - prc: 0.9864\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0311 - prc: 0.9793\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0311 - prc: 0.9838\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0241 - prc: 0.9905\n",
      "36/36 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-02 08:43:15.890091: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1959 - prc: 0.7710\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.1145 - prc: 0.8318\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0902 - prc: 0.8883\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0761 - prc: 0.9179\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0715 - prc: 0.9234\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0714 - prc: 0.9209\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0635 - prc: 0.9374\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0588 - prc: 0.9440\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0531 - prc: 0.9569\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0487 - prc: 0.9648\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0502 - prc: 0.9586\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0459 - prc: 0.9682\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0447 - prc: 0.9690\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0423 - prc: 0.9746\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0410 - prc: 0.9741\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0397 - prc: 0.9718\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0485 - prc: 0.9620\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0399 - prc: 0.9757\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0396 - prc: 0.9748\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0431 - prc: 0.9687\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0336 - prc: 0.9828\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0310 - prc: 0.9861\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0362 - prc: 0.9792\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0276 - prc: 0.9903\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0287 - prc: 0.9880\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0322 - prc: 0.9843\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0356 - prc: 0.9753\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0297 - prc: 0.9857\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0310 - prc: 0.9848\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0260 - prc: 0.9900\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0294 - prc: 0.9858\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0269 - prc: 0.9884\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0268 - prc: 0.9876\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0203 - prc: 0.9949\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0250 - prc: 0.9902\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0227 - prc: 0.9915\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0250 - prc: 0.9902\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0250 - prc: 0.9895\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0286 - prc: 0.9860\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0250 - prc: 0.9886\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0288 - prc: 0.9855\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0276 - prc: 0.9862\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0211 - prc: 0.9935\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0273 - prc: 0.9848\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0206 - prc: 0.9905\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0270 - prc: 0.9877\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0239 - prc: 0.9887\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0197 - prc: 0.9940\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0209 - prc: 0.9927\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0162 - prc: 0.9957\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0191 - prc: 0.9940\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0200 - prc: 0.9926\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0199 - prc: 0.9935\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0303 - prc: 0.9866\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0270 - prc: 0.9816\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0230 - prc: 0.9902\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0170 - prc: 0.9948\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0159 - prc: 0.9963\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0149 - prc: 0.9935\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0156 - prc: 0.9962\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0145 - prc: 0.9971\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0158 - prc: 0.9955\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0206 - prc: 0.9883\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0174 - prc: 0.9951\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0202 - prc: 0.9896\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0263 - prc: 0.9876\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0259 - prc: 0.9855\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0164 - prc: 0.9952\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0138 - prc: 0.9966\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0164 - prc: 0.9943\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0172 - prc: 0.9936\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0148 - prc: 0.9962\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0150 - prc: 0.9936\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0149 - prc: 0.9962\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0117 - prc: 0.9981\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0157 - prc: 0.9953\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0227 - prc: 0.9878\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0183 - prc: 0.9936\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0151 - prc: 0.9963\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0116 - prc: 0.9980\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0147 - prc: 0.9962\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0110 - prc: 0.9980\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0134 - prc: 0.9969\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0149 - prc: 0.9953\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0124 - prc: 0.9975\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0131 - prc: 0.9937\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0130 - prc: 0.9974\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0108 - prc: 0.9984\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0197 - prc: 0.9927\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0207 - prc: 0.9906\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0241 - prc: 0.9886\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0232 - prc: 0.9878\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0139 - prc: 0.9965\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0182 - prc: 0.9901\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0148 - prc: 0.9953\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0099 - prc: 0.9987\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0112 - prc: 0.9950\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0130 - prc: 0.9970\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0124 - prc: 0.9974\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0090 - prc: 0.9987\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.1040 - prc: 0.9008\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0581 - prc: 0.9454\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0555 - prc: 0.9514\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0494 - prc: 0.9599\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0369 - prc: 0.9766\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0284 - prc: 0.9863\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0306 - prc: 0.9830\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0329 - prc: 0.9787\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0247 - prc: 0.9895\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0202 - prc: 0.9926\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0221 - prc: 0.9920\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0205 - prc: 0.9916\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0176 - prc: 0.9951\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0240 - prc: 0.9896\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0230 - prc: 0.9887\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0185 - prc: 0.9942\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0158 - prc: 0.9960\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0201 - prc: 0.9915\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0134 - prc: 0.9977\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0136 - prc: 0.9975\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0118 - prc: 0.9985\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0120 - prc: 0.9961\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0148 - prc: 0.9938\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0146 - prc: 0.9962\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0128 - prc: 0.9974\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0214 - prc: 0.9906\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0170 - prc: 0.9948\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0234 - prc: 0.9919\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0211 - prc: 0.9909\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0158 - prc: 0.9956\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0152 - prc: 0.9959\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0132 - prc: 0.9968\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0137 - prc: 0.9960\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0143 - prc: 0.9936\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0134 - prc: 0.9971\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0122 - prc: 0.9974\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0132 - prc: 0.9968\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0103 - prc: 0.9985\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0142 - prc: 0.9965\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0132 - prc: 0.9947\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0149 - prc: 0.9960\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0168 - prc: 0.9952\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0146 - prc: 0.9965\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0128 - prc: 0.9971\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0150 - prc: 0.9959\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0161 - prc: 0.9946\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0179 - prc: 0.9931\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0153 - prc: 0.9957\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0154 - prc: 0.9940\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0091 - prc: 0.9988\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0171 - prc: 0.9939\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0222 - prc: 0.9858\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0218 - prc: 0.9895\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0151 - prc: 0.9947\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0142 - prc: 0.9967\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0138 - prc: 0.9896\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0097 - prc: 0.9991\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0104 - prc: 0.9981\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0138 - prc: 0.9962\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0112 - prc: 0.9979\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0143 - prc: 0.9962\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0133 - prc: 0.9938\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0094 - prc: 0.9987\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0105 - prc: 0.9982\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0077 - prc: 0.9993\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0063 - prc: 0.9994\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0131 - prc: 0.9940\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0159 - prc: 0.9953\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0127 - prc: 0.9948\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0092 - prc: 0.9989\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0072 - prc: 0.9994\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0089 - prc: 0.9985\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0128 - prc: 0.9957\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0094 - prc: 0.9986\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0076 - prc: 0.9991\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0111 - prc: 0.9979\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0119 - prc: 0.9970\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0175 - prc: 0.9908\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0197 - prc: 0.9891\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0136 - prc: 0.9965\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 1s 10ms/step - loss: 0.0102 - prc: 0.9982\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0085 - prc: 0.9987\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0083 - prc: 0.9984\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0070 - prc: 0.9992\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0064 - prc: 0.9994\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0065 - prc: 0.9993\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0061 - prc: 0.9994\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0072 - prc: 0.9988\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0104 - prc: 0.9955\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0132 - prc: 0.9968\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0178 - prc: 0.9922\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0210 - prc: 0.9865\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0189 - prc: 0.9890\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0173 - prc: 0.9943\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0112 - prc: 0.9964\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0133 - prc: 0.9966\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0123 - prc: 0.9969\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0147 - prc: 0.9947\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0142 - prc: 0.9961\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0098 - prc: 0.9984\n",
      "36/36 [==============================] - 0s 2ms/step\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0818 - prc: 0.9324\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0444 - prc: 0.9640\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0247 - prc: 0.9860\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0213 - prc: 0.9909\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0206 - prc: 0.9907\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0191 - prc: 0.9930\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0192 - prc: 0.9936\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0177 - prc: 0.9918\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0112 - prc: 0.9982\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0108 - prc: 0.9951\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0115 - prc: 0.9976\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0099 - prc: 0.9984\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0119 - prc: 0.9935\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0215 - prc: 0.9870\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0225 - prc: 0.9948\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0108 - prc: 0.9981\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0119 - prc: 0.9972\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0111 - prc: 0.9979\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0088 - prc: 0.9988\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0141 - prc: 0.9922\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0086 - prc: 0.9985\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0082 - prc: 0.9990\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0095 - prc: 0.9983\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0086 - prc: 0.9982\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0120 - prc: 0.9936\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0144 - prc: 0.9965\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0138 - prc: 0.9940\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0125 - prc: 0.9957\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0124 - prc: 0.9971\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0106 - prc: 0.9980\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0088 - prc: 0.9972\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0125 - prc: 0.9967\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0141 - prc: 0.9934\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0144 - prc: 0.9947\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0190 - prc: 0.9920\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0181 - prc: 0.9912\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0157 - prc: 0.9921\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0178 - prc: 0.9960\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0089 - prc: 0.9987\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0087 - prc: 0.9988\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0134 - prc: 0.9965\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0130 - prc: 0.9947\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0125 - prc: 0.9965\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0092 - prc: 0.9986\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0113 - prc: 0.9970\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0083 - prc: 0.9961\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0093 - prc: 0.9986\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0121 - prc: 0.9945\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0112 - prc: 0.9963\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0167 - prc: 0.9892\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0114 - prc: 0.9978\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0060 - prc: 0.9995\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0073 - prc: 0.9990\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0055 - prc: 0.9996\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0139 - prc: 0.9942\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0123 - prc: 0.9946\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0057 - prc: 0.9996\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0075 - prc: 0.9991\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0099 - prc: 0.9982\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0099 - prc: 0.9981\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0080 - prc: 0.9976\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0066 - prc: 0.9991\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0108 - prc: 0.9955\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0074 - prc: 0.9991\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0151 - prc: 0.9953\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0103 - prc: 0.9981\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0195 - prc: 0.9871\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0122 - prc: 0.9973\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0177 - prc: 0.9902\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0138 - prc: 0.9929\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0091 - prc: 0.9986\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0073 - prc: 0.9992\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0083 - prc: 0.9987\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0102 - prc: 0.9981\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0099 - prc: 0.9984\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0120 - prc: 0.9974\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0075 - prc: 0.9990\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0078 - prc: 0.9974\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0147 - prc: 0.9952\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0391 - prc: 0.9901\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0115 - prc: 0.9946\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0150 - prc: 0.9948\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0103 - prc: 0.9975\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0115 - prc: 0.9962\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0104 - prc: 0.9956\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0107 - prc: 0.9978\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0068 - prc: 0.9995\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0133 - prc: 0.9969\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0104 - prc: 0.9980\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0085 - prc: 0.9985\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0074 - prc: 0.9979\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0078 - prc: 0.9989\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0064 - prc: 0.9991\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0085 - prc: 0.9961\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0035 - prc: 0.9999\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0077 - prc: 0.9970\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0077 - prc: 0.9988\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0074 - prc: 0.9961\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0035 - prc: 0.9999\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0054 - prc: 0.9996\n",
      "36/36 [==============================] - 0s 3ms/step\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0379 - prc: 0.9743\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0322 - prc: 0.9750\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0266 - prc: 0.9854\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0178 - prc: 0.9939\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0138 - prc: 0.9931\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0117 - prc: 0.9934\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0087 - prc: 0.9987\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0115 - prc: 0.9937\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0126 - prc: 0.9951\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0094 - prc: 0.9983\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0087 - prc: 0.9986\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0111 - prc: 0.9978\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0094 - prc: 0.9957\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0077 - prc: 0.9991\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0115 - prc: 0.9938\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0139 - prc: 0.9958\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0136 - prc: 0.9963\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0157 - prc: 0.9892\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0104 - prc: 0.9980\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0099 - prc: 0.9984\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0149 - prc: 0.9932\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0095 - prc: 0.9982\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0127 - prc: 0.9958\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0054 - prc: 0.9996\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0104 - prc: 0.9980\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0064 - prc: 0.9967\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0064 - prc: 0.9978\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0086 - prc: 0.9984\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0229 - prc: 0.9973\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0080 - prc: 0.9986\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0055 - prc: 0.9995\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0098 - prc: 0.9981\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0087 - prc: 0.9987\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0146 - prc: 0.9939\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0089 - prc: 0.9986\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0161 - prc: 0.9923\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0101 - prc: 0.9983\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0147 - prc: 0.9965\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0085 - prc: 0.9988\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0092 - prc: 0.9984\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0115 - prc: 0.9932\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0089 - prc: 0.9958\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0090 - prc: 0.9971\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0075 - prc: 0.9988\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 1s 11ms/step - loss: 0.0049 - prc: 0.9997\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 1s 12ms/step - loss: 0.0060 - prc: 0.9994\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0059 - prc: 0.9995\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0061 - prc: 0.9993\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0098 - prc: 0.9956\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0131 - prc: 0.9955\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0099 - prc: 0.9981\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0112 - prc: 0.9978\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0107 - prc: 0.9975\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0053 - prc: 0.9997\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0065 - prc: 0.9992\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0079 - prc: 0.9948\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0066 - prc: 0.9977\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0069 - prc: 0.9977\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0086 - prc: 0.9984\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0180 - prc: 0.9934\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0102 - prc: 0.9981\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0097 - prc: 0.9982\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0149 - prc: 0.9941\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0075 - prc: 0.9988\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0047 - prc: 0.9997\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0056 - prc: 0.9992\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0070 - prc: 0.9989\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0061 - prc: 0.9991\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0072 - prc: 0.9976\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0099 - prc: 0.9965\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0098 - prc: 0.9981\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0066 - prc: 0.9991\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0068 - prc: 0.9991\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0078 - prc: 0.9965\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0060 - prc: 0.9993\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0093 - prc: 0.9984\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0076 - prc: 0.9990\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0106 - prc: 0.9916\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0078 - prc: 0.9973\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0030 - prc: 0.9998\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0043 - prc: 0.9997\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0072 - prc: 0.9965\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 1s 15ms/step - loss: 0.0124 - prc: 0.9960\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0114 - prc: 0.9963\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0136 - prc: 0.9918\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0131 - prc: 0.9970\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0067 - prc: 0.9993\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0104 - prc: 0.9971\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0056 - prc: 0.9979\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0070 - prc: 0.9989\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0038 - prc: 0.9999\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0090 - prc: 0.9986\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0119 - prc: 0.9954\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0111 - prc: 0.9935\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0085 - prc: 0.9987\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 1s 14ms/step - loss: 0.0072 - prc: 0.9989\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0091 - prc: 0.9971\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0067 - prc: 0.9992\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0048 - prc: 0.9996\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 1s 13ms/step - loss: 0.0054 - prc: 0.9996\n",
      "36/36 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "resample = NeighbourhoodCleaningRule() \n",
    "y = y_values\n",
    "k = 5\n",
    "ep = 75\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X_test =  scaler.transform(X) \n",
    "Train_shape = X.shape\n",
    "\n",
    "X = X.reshape(int(Train_shape[0]/numberOfWindows),numberOfWindows,numberOfFeatures)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "# enumerate the splits and summarize the distributions\n",
    "\n",
    "for train_ix, val_ix in skf.split(X,y):\n",
    "    # select rows\n",
    "    X_train, X_val = X[train_ix], X[val_ix]\n",
    "    y_train, y_val = y[train_ix], y[val_ix]\n",
    "    \n",
    "    resample.fit_resample(X_train[:,:,0], y_train)\n",
    "    X_train_2 = X_train[resample.sample_indices_]\n",
    "    y_train_2 = y_train[resample.sample_indices_]\n",
    "\n",
    "    history4 = model.fit(X_train,y_train, epochs = ep,batch_size=64)\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = list(map(lambda x: 0 if x<0.5 else 1, y_pred))\n",
    "    #class_labels = np.argmax(y_pred, axis=1)\n",
    "    y_actu = pd.Series(y_val)\n",
    "    y_pred = pd.Series(y_pred)\n",
    "     \n",
    "    sensitivity = recall_score(y_actu, y_pred,pos_label = 1, average='binary')\n",
    "    precision = precision_score(y_actu, y_pred,pos_label = 1, average='binary')\n",
    "    f1_value = f1_score(y_actu, y_pred,pos_label = 1, average='binary')\n",
    "    prc = average_precision_score(y_actu, y_pred,pos_label = 1)\n",
    "    roc = roc_auc_score(y_actu, y_pred)\n",
    "    accuracy = accuracy_score(y_actu, y_pred)\n",
    "    \n",
    "    acc_score.append(accuracy)\n",
    "    re_score.append(sensitivity)\n",
    "    pre_score.append(precision)\n",
    "    f_score.append(f1_value)\n",
    "    auroc.append(roc)\n",
    "    auprc.append(prc)\n",
    "   \n",
    "avg_acc_score = sum(acc_score)/k\n",
    "avg_recall_score = sum(re_score)/k\n",
    "avg_precision_score = sum(pre_score)/k\n",
    "avg_f1_score = sum(f_score)/k\n",
    "avg_roc_score = sum(auroc)/k\n",
    "avg_prc_score = sum(auprc)/k\n",
    "\n",
    "sensitivity = avg_recall_score\n",
    "precision = avg_precision_score\n",
    "accuracy = avg_acc_score\n",
    "f1_score = avg_f1_score\n",
    "auroc = avg_roc_score\n",
    "auprc = avg_prc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of each fold - [0.8924825174825175, 0.9388111888111889, 0.9676573426573427, 0.9816433566433567, 0.9798775153105862]\n",
      "Avg accuracy : 0.9520943841809985\n",
      "Recall of each fold - [0.2912621359223301, 0.5533980582524272, 0.75, 0.8269230769230769, 0.8252427184466019]\n",
      "Avg Reccall : 0.6493651979088872\n",
      "Precision of each fold - [0.375, 0.7037037037037037, 0.8764044943820225, 0.9662921348314607, 0.9444444444444444]\n",
      "Avg Precision : 0.7731689554723262\n",
      "F1_Score of each fold - [0.32786885245901637, 0.6195652173913044, 0.8082901554404146, 0.8911917098445596, 0.8808290155440415]\n",
      "Avg F1_score : 0.7055489901358672\n",
      "AUROC of each fold - 0.8157471264058588\n",
      "Avg AUROC : 0.8157471264058588\n",
      "AUPRC of each fold - 0.5785261300094333\n",
      "Avg AUPRC : 0.5785261300094333\n"
     ]
    }
   ],
   "source": [
    "print('accuracy of each fold - {}'.format(acc_score))\n",
    "print('Avg accuracy : {}'.format(avg_acc_score))\n",
    "print('Recall of each fold - {}'.format(re_score))\n",
    "print('Avg Reccall : {}'.format(avg_recall_score))\n",
    "print('Precision of each fold - {}'.format(pre_score))\n",
    "print('Avg Precision : {}'.format(avg_precision_score))\n",
    "print('F1_Score of each fold - {}'.format(f_score))\n",
    "print('Avg F1_score : {}'.format(avg_f1_score))\n",
    "print('AUROC of each fold - {}'.format(auroc))\n",
    "print('Avg AUROC : {}'.format(avg_roc_score))\n",
    "print('AUPRC of each fold - {}'.format(auprc))\n",
    "print('Avg AUPRC : {}'.format(avg_prc_score))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "\n",
    "csv_columns = ['model-type','precision','sensitivity','f1-score','accuracy','AUROC','AUPRC','NumberOfWindows','Epochs','AUROC','AUPRC']\n",
    "dict_data = [{'model-type':'CNN', 'precision': precision,'sensitivity': sensitivity,'f1-score': f1_score,'accuracy': accuracy,'NumberOfWindows':numberOfWindows,\"Epochs\":ep,'AUROC':auroc,'AUPRC':auprc}]\n",
    "metric_file = \"Results/Results_CNN.csv\"\n",
    "\n",
    "file_exists = os.path.isfile(metric_file)\n",
    "try:\n",
    "    with open(metric_file, 'a') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        for data in dict_data:\n",
    "            writer.writerow(data)\n",
    "except IOError:\n",
    "    print(\"I/O error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48feb6360a00eb0f47f9c89bd4d436ba37b01dbe1c2db3c2c6dfcc0146625bee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
