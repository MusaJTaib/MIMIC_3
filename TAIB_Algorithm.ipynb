{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9027639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d237ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(feature_set, column, number_of_windows):\n",
    "    \"\"\"\n",
    "    Preprocess the feature set for a specific column and window size.\n",
    "    \"\"\"\n",
    "    feature_set_b = pd.DataFrame({\n",
    "        'SubjectId': feature_set['SubjectId'],\n",
    "        'value': feature_set[column]\n",
    "    })\n",
    "    \n",
    "    # Filter and reset the index for ClientId\n",
    "    client_id = feature_set_b['SubjectId'].drop_duplicates(keep='first').reset_index(drop=True)\n",
    "    \n",
    "    return feature_set_b, client_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa3c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_separation(feature_set_b, feature_mortality, number_of_windows):\n",
    "    \"\"\"\n",
    "    Calculate the normalized separation distance average (nrmSepDA) for the feature set.\n",
    "    \"\"\"\n",
    "    # Preprocess mortality feature set\n",
    "    feature_mortality_filtered = feature_mortality[feature_mortality['SubjectId'].isin(feature_set_b['SubjectId'])]\n",
    "    feature_mortality_filtered.sort_values(by=['SubjectId'], ascending=True, inplace=True)\n",
    "    \n",
    "    client_id = feature_mortality_filtered['SubjectId'].drop_duplicates(keep='first').reset_index(drop=True)\n",
    "    \n",
    "    feature_set_b_filtered = feature_set_b[feature_set_b['SubjectId'].isin(client_id)]\n",
    "    \n",
    "    y = feature_mortality_filtered['Death'].values\n",
    "    x = feature_set_b_filtered['value'].values.reshape(-1, number_of_windows)\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    x_scaled = scaler.fit_transform(x)\n",
    "    \n",
    "    # Calculate the centroids\n",
    "    x_0 = x_scaled[y == 0]\n",
    "    x_1 = x_scaled[y == 1]\n",
    "    \n",
    "    cent_neg = np.mean(x_0, axis=0)\n",
    "    cent_pos = np.mean(x_1, axis=0)\n",
    "    \n",
    "    # Calculate the separation distance using DTW\n",
    "    cent_sep_d, _ = fastdtw(cent_neg, cent_pos, dist=euclidean)\n",
    "    \n",
    "    pos_sep_d = np.mean([fastdtw(cent_neg, row, dist=euclidean)[0] for row in x_1])\n",
    "    neg_sep_d = np.mean([fastdtw(cent_pos, row, dist=euclidean)[0] for row in x_0])\n",
    "    \n",
    "    nrm_sep_da = (pos_sep_d + neg_sep_d) / 2\n",
    "    return nrm_sep_da\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4837dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "feature_mortality = pd.read_csv('FeatureMortality.csv') # Adjust the file path as needed\n",
    "\n",
    "for number_of_windows in [1, 2, 3, 6, 12, 45, 90]:\n",
    "    file_name = f'MIMIC/DATA_{number_of_windows}.csv'\n",
    "    feature_set = pd.read_csv(file_name)\n",
    "    feature_set.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "    feature_set.sort_values(by=['SubjectId'], ascending=True, inplace=True)\n",
    "    \n",
    "    for column in feature_set.columns:\n",
    "        if column == 'SubjectId':\n",
    "            continue\n",
    "        \n",
    "        feature_set_b, client_id = preprocess_features(feature_set, column, number_of_windows)\n",
    "        nrm_sep_da = calculate_separation(feature_set_b, feature_mortality, number_of_windows)\n",
    "        \n",
    "        results.append({\n",
    "            'Window Size': number_of_windows,\n",
    "            'Column': column,\n",
    "            'nrmSepDA': nrm_sep_da\n",
    "        })\n",
    "\n",
    "# Calculate gradients and save results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df['Gradient'] = results_df.groupby('Column')['nrmSepDA'].transform(np.gradient)\n",
    "results_df.to_csv('Gradient_Results.csv', index=False)\n",
    "\n",
    "print(\"Processing and saving complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
